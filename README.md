# ERA



## Session-5 [Basic MNIST Model Training and Evaluation]

- Setup
- Import Dataset and create Dataloader
- Perform Transforms
- Visualize Model loss and accuracy on training and test dataset



## Session-6 [BackPropagation]

- Explanation of Backpropagation algorithm
- Example - simple network
- Calculation of all the gradients and performing backpropagation
- Weight update steps and model training explanation
- All the calculations in Excel file
- Effect of learning rate on loss and weight update



## Session-7 [Model Creation Process]

- All the steps to be followed for model creation
- 8 steps followed to create a model to achieve 99.4% accuracy under 15 epochs within 8000 parameters



## Session-8 [Normalization and Regularization]

- Basic Concepts
- Normalization and types of normalizations used in DL (Batch, Layer and Group)
- Regularization (L1 & L2)
- Implementation of normalization and Regularization in PyTorch
- Comparison of model with different types of normalization techniques
- Simple model to achieve 70% accuracy on CIFAR10 dataset



## Session-9 [Advance Convolutions]

- Different types of convolutions used in the DL models
- Implementation of these convolutions in PyTorch
- Model to achieve 85% on CIFAR under 50,000 parameters



## Session-10 [One Cycle Policy]

- Implementation of One Cycle Policy for faster training of models
- Model to achieve 90%+ accuracy on CIFAR10 in 24 epochs



## Session-11 [GradCam]

- Train ResNet18 for 20 epochs with 85+% accuracy
- Implemented GradCam to visualize the network activations for four block of the ResNet on the misclassified images

